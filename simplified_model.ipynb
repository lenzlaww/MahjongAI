{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9079749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3113e63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c660994",
   "metadata": {},
   "source": [
    "# y label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6569c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks_tiles_newlined = [\n",
    "    \"1\\nman\",\n",
    "    \"2\\nman\",\n",
    "    \"3\\nman\",\n",
    "    \"4\\nman\",\n",
    "    \"5\\nman\",\n",
    "    \"6\\nman\",\n",
    "    \"7\\nman\",\n",
    "    \"8\\nman\",\n",
    "    \"9\\nman\",\n",
    "    \"1\\npin\",\n",
    "    \"2\\npin\",\n",
    "    \"3\\npin\",\n",
    "    \"4\\npin\",\n",
    "    \"5\\npin\",\n",
    "    \"6\\npin\",\n",
    "    \"7\\npin\",\n",
    "    \"8\\npin\",\n",
    "    \"9\\npin\",\n",
    "    \"1\\nsou\",\n",
    "    \"2\\nsou\",\n",
    "    \"3\\nsou\",\n",
    "    \"4\\nsou\",\n",
    "    \"5\\nsou\",\n",
    "    \"6\\nsou\",\n",
    "    \"7\\nsou\",\n",
    "    \"8\\nsou\",\n",
    "    \"9\\nsou\",\n",
    "    \"\\nEast\",\n",
    "    \"\\nSouth\",\n",
    "    \"\\nWest\",\n",
    "    \"\\nNorth\",\n",
    "    \"\\nHaku\",\n",
    "    \"\\nHatsu\",\n",
    "    \"\\nChun\"\n",
    "]\n",
    "\n",
    "ticks_tiles_oneline = [\n",
    "    \"1 man\",\n",
    "    \"2 man\",\n",
    "    \"3 man\",\n",
    "    \"4 man\",\n",
    "    \"5 man\",\n",
    "    \"6 man\",\n",
    "    \"7 man\",\n",
    "    \"8 man\",\n",
    "    \"9 man\",\n",
    "    \"1 pin\",\n",
    "    \"2 pin\",\n",
    "    \"3 pin\",\n",
    "    \"4 pin\",\n",
    "    \"5 pin\",\n",
    "    \"6 pin\",\n",
    "    \"7 pin\",\n",
    "    \"8 pin\",\n",
    "    \"9 pin\",\n",
    "    \"1 sou\",\n",
    "    \"2 sou\",\n",
    "    \"3 sou\",\n",
    "    \"4 sou\",\n",
    "    \"5 sou\",\n",
    "    \"6 sou\",\n",
    "    \"7 sou\",\n",
    "    \"8 sou\",\n",
    "    \"9 sou\",\n",
    "    \"East\",\n",
    "    \"South\",\n",
    "    \"West\",\n",
    "    \"North\",\n",
    "    \"Haku\",\n",
    "    \"Hatsu\",\n",
    "    \"Chun\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928e632",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43510bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_data_options(code: str):\n",
    "    results = [False, False, False]\n",
    "    code = int(f\"0b{code:0>11}\", 2)\n",
    "    results[0] = code & 0b100 != 0\n",
    "    results[1] = code & 0b010 != 0\n",
    "    results[2] = code & 0b001 != 0\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdbf519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class DiscardDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    class DiscardType(Enum):\n",
    "        DISCARD = 0\n",
    "        POOL    = 1\n",
    "\n",
    "    def __init__(self, data_path, years: list, n_rows: int = None, phase: int = None, balance_data: bool = False, discard_type=DiscardType.DISCARD, singular=False):\n",
    "        \"\"\" \n",
    "        If n_rows = None -> get all \n",
    "        param: singular: If True, pick 1 state per game at random!\n",
    "        \"\"\" \n",
    "        \n",
    "        # FORCE SEED\n",
    "        torch.manual_seed(0)\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        # Invalid Parameter Combinations\n",
    "        if balance_data:\n",
    "            if not n_rows:\n",
    "                raise BaseException(\"`n_rows` must be defined if `balance_data` is True!\")\n",
    "            elif n_rows < 34:\n",
    "                raise BaseException(\"Cannot balance data if `n_rows` < 34!\")\n",
    "        \n",
    "        # ALL_YEARS = (2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019)\n",
    "        # invalid_years = set(years) - set(ALL_YEARS)\n",
    "        # if invalid_years:\n",
    "        #     raise Exception(f\"INVALID YEARS: {invalid_years}\")\n",
    "        \n",
    "        # Dataset Print\n",
    "        if n_rows:\n",
    "            print(f\"Loading Dataset with {n_rows:>13,} rows\", end=' ')\n",
    "        else:\n",
    "            print(f\"Loading Dataset with all rows\", end=' ')\n",
    "\n",
    "        if phase in [0, 1, 2]:\n",
    "            print(f\"(Phase {phase})\", end=' ')\n",
    "        else:\n",
    "            print(f\"(All Phases)\", end=' ')\n",
    "            \n",
    "        print(\"{:<14}\".format(\"<BALANCED>\" if balance_data else '<NOT BALANCED>'), end=' ')\n",
    "        \n",
    "        # print(years)\n",
    "        \n",
    "        # Check if given discard_type is valid\n",
    "        if discard_type not in [DiscardDataset.DiscardType.DISCARD, DiscardDataset.DiscardType.POOL]:\n",
    "            raise BaseException(f\"INVALID discard type = {discard_type}! Use either `DiscardDataset.DISCARD` or `DiscardDataset.POOL`!\")\n",
    "        self.discard_type = discard_type\n",
    "\n",
    "        game_id_list = []\n",
    "        temp_matrices = []\n",
    "        finished = False\n",
    "        \n",
    "        # Used when balance_data = False and n_rows != None\n",
    "        loaded_rows = 0  \n",
    "        \n",
    "        # Used when balance_data = True\n",
    "        class_bins = np.zeros(34)\n",
    "        baseline_bin_size = n_rows // 34 if balance_data else -1  # The expected size of the smallest bin\n",
    "\n",
    "        if balance_data:\n",
    "            paths_load_bar = tqdm(total=baseline_bin_size * 34, unit='rows', position=0)\n",
    "        else:\n",
    "            paths_load_bar = tqdm(total=n_rows, unit='rows', position=0)\n",
    "\n",
    "        # for year in years:\n",
    "        year = 2019\n",
    "\n",
    "        paths = data_path.iterdir()\n",
    "\n",
    "        for idx, path in enumerate(paths):\n",
    "            \n",
    "            if path.suffix != '.npz':\n",
    "                continue\n",
    "            \n",
    "            game_id_list.append(path.stem)\n",
    "\n",
    "            arr = scipy.sparse.load_npz(path).toarray()  # Loads a single complete game\n",
    "\n",
    "            if phase in [0, 1, 2]:\n",
    "                phased_matrices = self.generate_phase_column(arr)\n",
    "                arr = phased_matrices[phase]\n",
    "                \n",
    "            if singular:\n",
    "                if arr.shape[0] <= 0:  # No rows found (This can happen if a game lack states from a certain phase)\n",
    "                    continue\n",
    "                random_row_index = np.random.choice(arr.shape[0], 1, replace=False)\n",
    "                arr = arr[random_row_index]  # Select 1 row per loaded game\n",
    "\n",
    "            temp_matrices.append(arr)\n",
    "\n",
    "            paths_load_bar.set_postfix(year=year, files_loaded=(idx + 1))  # Update Bar\n",
    "\n",
    "            if balance_data:\n",
    "                \n",
    "                class_bins += np.bincount(arr[:, -1], minlength=34)\n",
    "                smallest_class_bin = int(np.amin(class_bins))\n",
    "\n",
    "                paths_load_bar.n = smallest_class_bin * 34\n",
    "                paths_load_bar.refresh()\n",
    "                \n",
    "                if baseline_bin_size <= smallest_class_bin:\n",
    "                    finished = True\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                paths_load_bar.update(arr.shape[0])\n",
    "                \n",
    "                if n_rows:\n",
    "                    loaded_rows += arr.shape[0]\n",
    "                    if n_rows <= loaded_rows:\n",
    "                        finished = True\n",
    "                        break\n",
    "\n",
    "        # if finished:  # Early Stopping\n",
    "        #     break\n",
    "\n",
    "        if not finished and n_rows is not None:\n",
    "            raise BaseException(\"`n_rows` is higher than found rows -- Either lower `n_rows` or include more annual datasets!\")\n",
    "\n",
    "        new_game_id_list = []\n",
    "        for i, t_matrix in enumerate(temp_matrices):\n",
    "            new_game_id_list.extend([game_id_list[i]] * t_matrix.shape[0])\n",
    "        new_game_id_list = np.array(new_game_id_list)\n",
    "        \n",
    "        if balance_data:\n",
    "            \n",
    "            matrix = np.concatenate(temp_matrices, axis=0)\n",
    "            sorted_indices = np.argsort(matrix[:, -1])\n",
    "            \n",
    "            matrix = matrix[sorted_indices]  # Sort rows by last column (the y-value)\n",
    "            new_game_id_list = new_game_id_list[sorted_indices]\n",
    "            \n",
    "            split_indices = np.where(np.diff(matrix[:, -1])!=0)[0]+1  # I was drunk\n",
    "            sorted_rows = np.array_split(matrix, split_indices)  # Organize rows according to their last column's value into a list\n",
    "            sorted_game_ids = np.array_split(new_game_id_list, split_indices)\n",
    "            \n",
    "            for i in range(len(sorted_rows)):\n",
    "                sorted_rows[i] = sorted_rows[i][:baseline_bin_size]  # The balancing action\n",
    "                sorted_game_ids[i] = sorted_game_ids[i][:baseline_bin_size]\n",
    "\n",
    "            final_arr = np.concatenate(sorted_rows, axis=0)\n",
    "            final_game_id_list = np.concatenate(sorted_game_ids, axis=0)\n",
    "\n",
    "        else:\n",
    "            final_arr = np.vstack(temp_matrices)\n",
    "            final_game_id_list = new_game_id_list\n",
    "            \n",
    "            if n_rows:\n",
    "                final_arr = final_arr[:n_rows]\n",
    "                final_game_id_list = final_game_id_list[:n_rows]\n",
    "                \n",
    "        # Extract Round Number and Steps from data\n",
    "        self.round_numbers = final_arr[:, 32].reshape(-1).tolist()\n",
    "        self.step_numbers  = (final_arr[:, 33] + 128 - 1).reshape(-1).tolist()        \n",
    "        final_arr[:, 32] = -128  # Reset to padding value\n",
    "        final_arr[:, 33] = -128  # Reset to padding value\n",
    "\n",
    "        # Finalize tqdm bar\n",
    "        paths_load_bar.n = final_arr.shape[0]\n",
    "        paths_load_bar.last_print_n = final_arr.shape[0]\n",
    "        paths_load_bar.refresh()\n",
    "        paths_load_bar.close()\n",
    "        \n",
    "        self.game_ids = list(final_game_id_list)\n",
    "        self.combined_x_data = torch.FloatTensor(final_arr[:, :-1])  # Must be Float it seems\n",
    "        \n",
    "        self.x_data = None\n",
    "        if self.discard_type == DiscardDataset.DiscardType.POOL:\n",
    "            self.use_pools()\n",
    "        else:\n",
    "            self.use_discards()\n",
    "        \n",
    "        self.y_data = torch.LongTensor(final_arr[:, -1])  # Must be Long it seems\n",
    "        \n",
    "    def use_pools(self):\n",
    "        self.discard_type = DiscardDataset.DiscardType.POOL\n",
    "        self.x_data = self.combined_x_data[:, 0:374]\n",
    "\n",
    "    def use_discards(self):\n",
    "        self.discard_type = DiscardDataset.DiscardType.DISCARD\n",
    "        self.x_data = torch.hstack((self.combined_x_data[:, :238], self.combined_x_data[:, 374:]))  # Slice away POOL data\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_phase_column(array: np.array) -> np.array:\n",
    "        # Begin with merging all pools together\n",
    "\n",
    "        merged_discards = array[:, 238:374]  # Pool\n",
    "        merged_discards = np.sum(merged_discards, axis=1)\n",
    "\n",
    "        phases = np.zeros([array.shape[0]])  # Early Game\n",
    "        phases[(24 < merged_discards) & (merged_discards <= 48)] = 1  # Mid Game\n",
    "        phases[(48 < merged_discards)] = 2  # End Game\n",
    "\n",
    "        return array[(phases == 0)], array[(phases == 1)], array[(phases == 2)]        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         X = self.x_data[idx, 0:374] if self.discard_type == DiscardDataset.DiscardType.POOL else torch.hstack((self.x_data[idx, :238], self.x_data[idx, 374:]))\n",
    "        return {\n",
    "            'game_id': self.game_ids[idx],\n",
    "            'round': self.round_numbers[idx],\n",
    "            'step': self.step_numbers[idx],\n",
    "            'X': self.x_data[idx],\n",
    "            'y': self.y_data[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c5c53f",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f7beb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 40000\n",
    "validation_size = 8000\n",
    "test_size = 4000\n",
    "batch_size = 32\n",
    "balanced_data  = 111\n",
    "PHASES = -1\n",
    "DISCARD_TYPE = DiscardDataset.DiscardType.POOL\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbdd13",
   "metadata": {},
   "source": [
    "# loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4bf306",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path('2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc6352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset with        40,000 rows (All Phases) <BALANCED>     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39984/39984 [00:00<00:00, 66641.12rows/s, files_loaded=351, year=2019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset with         8,000 rows (All Phases) <BALANCED>     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7990/7990 [00:39<00:00, 203.79rows/s, files_loaded=30718, year=2019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset with         4,000 rows (All Phases) <BALANCED>     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3978/3978 [00:20<00:00, 194.14rows/s, files_loaded=15856, year=2019]\n"
     ]
    }
   ],
   "source": [
    "BALANCED_TRAINING, BALANCED_VALIDATION, BALANCED_TEST = get_balanced_data_options(balanced_data) \n",
    "\n",
    "train_dataset = DiscardDataset(DATASET_PATH,\n",
    "                                   n_rows=train_size,\n",
    "                                   years=[],\n",
    "                                   phase=PHASES,\n",
    "                                   balance_data=BALANCED_TRAINING,\n",
    "                                   discard_type=DISCARD_TYPE\n",
    "                                  )\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_dataset = DiscardDataset(DATASET_PATH,\n",
    "                                        n_rows=validation_size,\n",
    "                                        years=[],\n",
    "                                        phase=PHASES,\n",
    "                                        balance_data=BALANCED_VALIDATION,\n",
    "                                        discard_type=DISCARD_TYPE,\n",
    "                                        singular=True\n",
    "                                       )\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = DiscardDataset(DATASET_PATH, \n",
    "                              n_rows=test_size, \n",
    "                              years=[],\n",
    "                              phase=PHASES,\n",
    "                              balance_data=BALANCED_TEST,\n",
    "                              discard_type=DISCARD_TYPE,\n",
    "                              singular=True\n",
    "                             )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54da9585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39984, 7990, 3978)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(validation_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07c58684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3978, 3978)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset.x_data), len(test_dataset.game_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21211e9c",
   "metadata": {},
   "source": [
    "# datachecker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "060cb56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupted Dataset Indices:\n",
      "    - Training Dataset:   []\n",
      "    - Validation Dataset: []\n",
      "    - Testing Dataset:    []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_corrupted_cases(dataset):\n",
    "    \"\"\" Return indices of corrupted X datas. \"\"\"\n",
    "    if dataset is not None:\n",
    "        return torch.nonzero(torch.sum(dataset.x_data[:, 68:102], dim=1) > 14).flatten().tolist()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "corrupt_datasets = [count_corrupted_cases(train_dataset), count_corrupted_cases(validation_dataset), count_corrupted_cases(test_dataset)]\n",
    "print(f\"\"\"Corrupted Dataset Indices:\n",
    "    - Training Dataset:   {corrupt_datasets[0]}\n",
    "    - Validation Dataset: {corrupt_datasets[1]}\n",
    "    - Testing Dataset:    {corrupt_datasets[2]}\n",
    "\"\"\")\n",
    "\n",
    "assert len(corrupt_datasets[0]) == 0 and len(corrupt_datasets[1]) == 0 and len(corrupt_datasets[2]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10a8f253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([32, 374])\n",
      "Label y shape: torch.Size([32])\n",
      "First input sample (x[0]): tensor([   1.,    2.,    1.,    0.,    0.,   47.,   17.,   27.,   25.,   31.,\n",
      "           0.,    0.,    0.,    0., -128., -128., -128., -128., -128., -128.,\n",
      "        -128., -128., -128., -128., -128., -128., -128., -128., -128., -128.,\n",
      "        -128., -128., -128., -128.,    0.,    0.,    0.,    0.,    1.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    2.,\n",
      "           1.,    0.,    0.,    0.,    1.,    1.,    1.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    1.,    1.,    1.,    0.,    0.,    0.,    1.,\n",
      "           2.,    0.,    0.,    1.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    1.,    1.,    1.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,\n",
      "           1.,    0.,    1.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,\n",
      "           0.,    0.,    2.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    1.,    0.,    1.,    1.,    0.,    1.,    0.,\n",
      "           1.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    1.,\n",
      "           0.,    1.,    0.,    1.])\n",
      "First label (y[0]): tensor(29)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    x = batch['X']  # Assuming your dataset returns a dict with 'X' and 'y'\n",
    "    y = batch['y']\n",
    "    \n",
    "    print(\"Input x shape:\", x.shape)  # e.g., torch.Size([32, 374])\n",
    "    print(\"Label y shape:\", y.shape)  # e.g., torch.Size([32])\n",
    "    \n",
    "    print(\"First input sample (x[0]):\", x[0])\n",
    "    print(\"First label (y[0]):\", y[0])\n",
    "    break  # Only one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9e3333a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAF0CAYAAACg3QoAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCnElEQVR4nO3de1hU1d4H8O+IMCACilwGFAFvqeGFwBLxghoqKuXxHPNShpc0QyoFy8gSpARvGZ08aqYHNNOsk3lJ83IUtY6YYHjJzCsIpUiigaKAzqz3D2Jexxl0ZpgZZuP38zzreZy111577dkUP9Zaey2ZEEKAiIiI6CEa1HUDiIiISBoYNBAREZFeGDQQERGRXhg0EBERkV4YNBAREZFeGDQQERGRXhg0EBERkV4YNBAREZFeGDQQERGRXhg0SEB6ejpkMhmys7PruilqycnJ2LRpk0nrzMvLg0wmQ3p6uknrNYafnx/GjRun/mzutv3yyy9ITExEXl6e1rFx48bBz8/PLNfVx/nz5yGXy5GZmanRpsaNG5uk/n379kEmk+E///mPSeq7t859+/YZXcfOnTsRGhoKBwcHuLi4IDIyEidPntQoc+fOHbRu3Rqpqam1azCRRDBoIKOYI2jw8vJCZmYmhgwZYtJ6TcHcbfvll18wZ84cnUHDu+++i2+++cYs19XHjBkzEB4ejpCQkDprg6Vt3rwZERER8PDwwNdff43ly5fj7Nmz6NWrF86fP68uZ2tri9mzZyMpKQnFxcV12GIiy2DQQFZDLpeje/fucHd3r+umaKnLtrVu3RqBgYEWvy4AnDp1Cps2bcKrr75aJ9evKzNnzkSnTp2wceNGDB48GKNHj8bOnTtRVlaG2bNna5QdPXo0ZDIZPvnkkzpqLZHlMGiQqOru4XPnzmHw4MFo3LgxfHx8EBcXh4qKCnW56m71BQsWYO7cuWjZsiXs7e0RHByMPXv2aNWpqxs8MTERMplM/Vkmk6GsrAyrV6+GTCaDTCZDWFiYznbeuXMHHh4eGDt2rNaxP//8Ew4ODoiNjdVo671DAH/88QcmT54MHx8fyOVyuLu7IzQ0FP/973/VZe4fSqgWFham0a7y8nLExcWha9eucHFxgaurK0JCQrB582adbb+XrrZV37uuVN1jkJ2djVGjRsHPzw8ODg7w8/PD6NGjcfHiRXU96enpGDFiBACgb9++6jqqr6XruZSXlyM+Ph7+/v6ws7ND8+bNMXXqVPz5558a5fz8/DB06FDs2LEDTzzxBBwcHNC+fXv8+9//fug9A8CyZcugUCgQHh6uV/l7nTt3DuPHj0fbtm3RqFEjNG/eHJGRkThx4oTO8uXl5YiNjYVCoYCDgwP69OmDnJwcrXLZ2dl45pln4OrqCnt7ewQGBuLLL780uH01KS4uxunTpxEREaHxc+/r64uAgABs2rQJSqVSnW9nZ4eRI0dixYoV4P5/VN8xaJCwO3fu4JlnnkH//v2xefNmTJgwAR9++CHmz5+vVXbJkiXYsWMHUlNTsXbtWjRo0AAREREa49T6yszMhIODAwYPHozMzExkZmZi6dKlOsva2trihRdewNdff43S0lKNY+vXr0d5eTnGjx9f47XGjh2LTZs2Yfbs2di1axdWrlyJp59+2qiu4IqKCly7dg0zZszApk2bsH79evTs2RPDhw/HmjVrDK6v+t6r0969e9G8eXMoFAq4uroCqAo2HnvsMaSmpmLnzp2YP38+Ll++jG7duuHq1asAgCFDhiA5ORkA8K9//UtdX01DIUIIDBs2DIsWLcLYsWOxbds2xMbGYvXq1ejXr59G0AgAx44dQ1xcHKZPn47Nmzejc+fOmDhxIg4cOPDQe9y2bRt69+6NBg0M/1/FpUuX0KxZM8ybNw87duzAv/71LzRs2BBPPfUUTp8+rVX+7bffxoULF7By5UqsXLkSly5dQlhYGC5cuKAuk5GRgdDQUPz5559Yvnw5Nm/ejK5du2LkyJEPnW9SHfjpCjDvVVlZCaCqd+l+crkct27d0hiiAKoC1IsXL+Lnn39+YN1EkifI6qWlpQkAIisrS50XFRUlAIgvv/xSo+zgwYPFY489pv6cm5srAAhvb29x+/ZtdX5paalwdXUVTz/9tEadvr6+WtdPSEgQ9/+oODo6iqioKL3af/z4cQFArFixQiP/ySefFEFBQVptTUtLU+c1btxYTJs27YH1+/r66mxLnz59RJ8+fWo87+7du+LOnTti4sSJIjAw8IF16mrb/XU9++yzonHjxuLIkSMPvObNmzeFo6Oj+Oijj9T5X331lQAgMjIytM65/7ns2LFDABALFizQKLdhwwat79nX11fY29uLixcvqvNu374tXF1dxcsvv1xjO4UQ4sqVKwKAmDdvns42OTo6PvD8+929e1dUVlaKtm3biunTp6vzMzIyBADxxBNPCJVKpc7Py8sTtra24qWXXlLntW/fXgQGBoo7d+5o1D106FDh5eUllEqlRp33fp95eXnCxsZGTJgw4YHtVCqVwtXVVfTv318j//r168LJyUkAEAcPHtQ4dvbsWQFALFu2TL8vg0ii2NMgYTKZDJGRkRp5nTt31uj6rjZ8+HDY29urPzs5OSEyMhIHDhzQ6Go1h06dOiEoKAhpaWnqvFOnTuHw4cOYMGHCA8998sknkZ6ejvfffx+HDh3CnTt3atWWr776CqGhoWjcuDEaNmwIW1tbrFq1CqdOnapVvTExMdi2bRu++uorPPHEE+r8mzdvYubMmWjTpg0aNmyIhg0bonHjxigrKzP6mnv37gUArb+YR4wYAUdHR61hp65du6Jly5bqz/b29mjXrp3On5N7Xbp0CQDg4eFhVDvv3r2L5ORkdOzYEXZ2dmjYsCHs7Oxw9uxZnfc+ZswYreGAHj16ICMjA0DVcMevv/6K559/Xl1/dRo8eDAuX76sswfj3vru3r2LVatWPbDdDRo0wNSpU7Fnzx689957KCoqwrlz5/DCCy/g1q1b6jL3qv6Ofv/9dz2+GSLpYtAgYY0aNdIIBICq7tPy8nKtsgqFQmdeZWUlbt68abY2VpswYQIyMzPx66+/AgDS0tIgl8sxevToB563YcMGREVFYeXKlQgJCYGrqytefPFFFBYWGtyGjRs34rnnnkPz5s2xdu1aZGZmIisrCxMmTND5nenr/fffx/Lly/HJJ59g0KBBGsfGjBmDJUuW4KWXXsLOnTtx+PBhZGVlwd3dHbdv3zbqesXFxWjYsKHWpEyZTAaFQqE1dNOsWTOtOuRy+UOvX338/p8xfcXGxuLdd9/FsGHDsHXrVvz444/IyspCly5ddF67pp/R6vu5cuUKgKq3OWxtbTVSdHQ0AKiHfGpr9uzZmD59Ot5//314enqibdu2AKAeSmvevLlG+ervyNhnSiQVDeu6AWQZun7JFhYWws7OTv2+vb29vdZ4OGCa/xGPHj0asbGxSE9Px9y5c/HZZ59h2LBhaNq06QPPc3NzQ2pqKlJTU5Gfn48tW7bgrbfeQlFREXbs2PHQdru5uak/r127Fv7+/tiwYYPGX7S6ztVXeno63n33XSQmJmr1mpSUlODbb79FQkIC3nrrLY3rXbt2zehrNmvWDHfv3sUff/yhETgIIVBYWIhu3boZXfe9qr87Y9u6du1avPjii+r5GtWuXr2KJk2aaJWv6We0Ouipbk98fDyGDx+u85qPPfaYUW29X8OGDbF48WIkJSUhNzcXbm5u8PLywsCBA+Hv748WLVpolK/+ju79eSOqj9jT8IjYuHGjxl/TN27cwNatW9GrVy/Y2NgAqJppX1RUpP6LDqiaFLZz506t+vT5S/VeTZs2xbBhw7BmzRp8++23KCwsfOjQxP1atmyJmJgYhIeH46efflLn+/n54fjx4xplz5w5o9VVLZPJYGdnpxEwFBYW6vX2hC47duzApEmTMGHCBCQkJGgdl8lkEEJoTahbuXKl1pBQdRl9vtP+/fsDqPqlfK+vv/4aZWVl6uO15evrCwcHB61Jf/qSyWRa975t27Yau/DXr1+v8fbBxYsXcfDgQfUbMI899hjatm2LY8eOITg4WGdycnIyqq01ady4MTp16gQvLy/89NNP2LNnD15//XWtctWTNTt27GjS6xNZG/Y0PCJsbGwQHh6O2NhYqFQqzJ8/H6WlpZgzZ466zMiRIzF79myMGjUKb7zxBsrLy/HPf/5T55yHTp06Yd++fdi6dSu8vLzg5OT00L/yJkyYgA0bNiAmJgYtWrTA008//cDyJSUl6Nu3L8aMGYP27dvDyckJWVlZ2LFjh8ZfmmPHjsULL7yA6Oho/P3vf8fFixexYMECre77oUOHYuPGjYiOjsY//vEPFBQU4L333oOXlxfOnj2rz9eolpubixEjRqBVq1YYP348Dh06pHE8MDAQzs7O6N27NxYuXAg3Nzf4+flh//79WLVqldZf2gEBAQCAFStWwMnJCfb29vD399c5tBAeHo6BAwdi5syZKC0tRWhoKI4fP46EhAQEBgbqfL3VGHZ2dggJCdG6t2pKpVLnKo6Ojo6IiIjA0KFDkZ6ejvbt26Nz5844cuQIFi5cqPVXerWioiL87W9/w6RJk1BSUoKEhATY29sjPj5eXeaTTz5BREQEBg4ciHHjxqF58+a4du0aTp06hZ9++glfffVVjfdz8eJFtG7dGlFRUQ+d17Bv3z5kZWWhc+fOEELg8OHDmD9/PgYNGoSYmBit8ocOHYKNjQ169+79wHqJJK9u52GSPmp6e0LX7PX733SonvU/f/58MWfOHNGiRQthZ2cnAgMDxc6dO7XO3759u+jatatwcHAQrVq1EkuWLNH59sTRo0dFaGioaNSokQDwwLcUqimVSuHj4yMAiFmzZmkdv/8NhfLycjFlyhTRuXNn4ezsLBwcHMRjjz0mEhISRFlZmfo8lUolFixYIFq1aiXs7e1FcHCw2Lt3r863J+bNmyf8/PyEXC4XHTp0EJ9++qnO+3vY2xPVs/NrSrm5uUIIIX777Tfx97//XTRt2lQ4OTmJQYMGiZ9//lnnGx+pqanC399f2NjYaFxL11stt2/fFjNnzhS+vr7C1tZWeHl5iVdeeUVcv35d6z6GDBmi9V0/7M2SaqtWrRI2Njbi0qVLGvnVb+/oStVtvX79upg4caLw8PAQjRo1Ej179hTff/+91rWrv8vPPvtMvPbaa8Ld3V3I5XLRq1cvkZ2drdWmY8eOieeee054eHgIW1tboVAoRL9+/cTy5cu16rz37YnqZ6jPWz//+9//xFNPPSWcnZ2FXC4XAQEBYtGiRaKyslJn+V69eonIyMiH1kskdTIhuBpJfZaXlwd/f38sXLgQM2bMqOvmkMSUl5ejZcuWiIuLw8yZM+u6OVbp/PnzaNu2LXbu3GnUIlhEUsI5DURUI3t7e8yZMweLFy9GWVlZXTfHKr3//vvo378/AwZ6JHBOAxE90OTJk/Hnn3/iwoUL6NSpU103x6rcvXsXrVu31ph3QVSfcXiCiIiI9MLhCSIiItILgwYiIiLSC4MGIiIi0ovVTYRUqVS4dOkSnJycNFbuIyIiaRFC4MaNG/D29jZqe3V9lJeXq7czN5SdnZ3Re6s8qqwuaLh06RJ8fHzquhlERGQiBQUFNa4EWhvl5eXw922MwiLjdupVKBTIzc1l4GAAqwsaqteO77RmKmwayR9SGtgfrr3mf0367k7Uu2xGuP5lDaG6Eqh32Vd/e0rvsm0ci/Que6XCWe+yd4WN3mUXdX3w0rzW5lmXF+u6CUT12l3cwQ/YbvI9QapVVlaisEiJ3CO+cHYyrCej9IYK/kEXUVlZyaDBAFYXNFQPSdg0kusVNDg76/8L0Mbx4fUZU68hVLf0/8G2a2ynd1l7R/0fpdzWVu+yDQwIGsz1nZlLQ5n+3wMRGeGvF/rNPdTs7NTA4KCBjGN1QQMREZEhlEIFpYErDimFyjyNqecYNBARkaSpIKCCYVGDoeWpCoMGIiKSNBVUMLTfwPAzCGDQQEREEqcUAkoDd0QwtDxVYdBARESSxuEJy+F0UyIiItILexqIiEjSVBBQsqfBIszW07B06VL4+/vD3t4eQUFB+P777811KSIieoRVD08YmshwZgkaNmzYgGnTpmHWrFnIyclBr169EBERgfz8fHNcjoiIHmHVEyENTWQ4swQNixcvxsSJE/HSSy+hQ4cOSE1NhY+PD5YtW2aOyxER0SNMZWQiw5k8aKisrMSRI0cwYMAAjfwBAwbg4MGDWuUrKipQWlqqkYiIiMj6mDxouHr1KpRKJTw9PTXyPT09UVhYqFU+JSUFLi4u6sQdLomIyBDKvyZCGprIcGabCHn/BiVCCJ2blsTHx6OkpESdCgoKzNUkIiKqh5TCuESGM/krl25ubrCxsdHqVSgqKtLqfQAAuVwOuVz/3SeJiIjuZcwcBc5pMI7Jexrs7OwQFBSE3bt3a+Tv3r0bPXr0MPXliIjoEaeCDEoDkwrm3a67vjLL4k6xsbEYO3YsgoODERISghUrViA/Px9Tpkwxx+WIiOgRphJVydBzyHBmCRpGjhyJ4uJiJCUl4fLlywgICMD27dvh6+trjssRERGRBZhtGeno6GhER0ebq3oiIiIAUA85GHoOGY57TxARkaQxaLAcBg1ERCRpKiGDShgWBBhanqpwa2wiIpI0Q9+cMKZnIjExETKZTCMpFAr1cSEEEhMT4e3tDQcHB4SFheHkyZOmvtU6x6CBiIgkTYkGRiVDPf7447h8+bI6nThxQn1swYIFWLx4MZYsWYKsrCwoFAqEh4fjxo0bprzVOseggYiISA8NGzaEQqFQJ3d3dwBVvQypqamYNWsWhg8fjoCAAKxevRq3bt3CunXr6rjVpsWggYiIJE38NafBkCT+mtNw/4aJFRUVNV7n7Nmz8Pb2hr+/P0aNGoULFy4AAHJzc1FYWKixUaNcLkefPn10btQoZQwaiIhI0mozp8HHx0dj08SUlBSd13jqqaewZs0a7Ny5E59++ikKCwvRo0cPFBcXq7dN0HejRimz2rcn9ocnwNnZ2aR1Hh6k+4fBkhoozupddpXi4WXIeLtVX9V1EyQl+Lu39S6bHZFsxpaQVJSWlsLFxcXs11GKBlAKw/4Grt6wqqCgQON3TU17IUVERKj/3alTJ4SEhKB169ZYvXo1unfvDkD/jRqljD0NREQkaSrIoEIDA1PVL3NnZ2eNpO8Gio6OjujUqRPOnj2rfotC340apYxBAxERSZolXrm8X0VFBU6dOgUvLy/4+/tDoVBobNRYWVmJ/fv317uNGq12eIKIiMhazJgxA5GRkWjZsiWKiorw/vvvo7S0FFFRUZDJZJg2bRqSk5PRtm1btG3bFsnJyWjUqBHGjBlT1003KQYNREQkacbNaTBsm8vffvsNo0ePxtWrV+Hu7o7u3bvj0KFD6o0Y33zzTdy+fRvR0dG4fv06nnrqKezatQtOTk4GXcfaMWggIiJJq5rTYOAy0gaW/+KLLx54XCaTITExEYmJiQbVKzUMGoiISNJURqzwqIJhPQ1UhUEDERFJmiWGJ6gKgwYiIpK06tcoDTuHQYMx+MolERER6YU9DUREJGlKIYNSGDax0dDyVIVBAxERSZoxW10rOTxhFAYNREQkaSrRACoDJ0KqOBHSKAwaiIhI0tjTYDkMGoiISNJUMHyOgso8Tan3+PYEERER6YU9DUREJGnGrdPAv5mNwaCBiIgkzbgVIRk0GINBAxERSZolNqyiKgwaiIhI0tjTYDkMGoiISNKMe+WSQYMx+K0RERGRXtjTQEREkqYSMqgMXaeBe08YhUEDERFJmsqI4Qm+cmkcBg1ERCRpxu09waDBGAwaiIhI0pSQQWngK5SGlqcqDBqIiEjS2NNgOfzWiIiISC+S72kI/u5ts9SbHZFslnqlxpDv15DvzBqe25M74vUua8hM6/r6s2Ou52uu78safsbMxZCf3cODUszSBn2+X+WtCrNcW+s6MHy4QWmeptR7kg8aiIjo0cbhCcth0EBERJLGZaQth0EDERFJmjBiwyrBtyeMwqCBiIgkjT0NlsNvjYiIiPTCoIGIiCSteu8JQ5MhUlJS0K1bNzg5OcHDwwPDhg3D6dOnNcqMGzcOMplMI3Xv3t2Ut1rnGDQQEZGkVW+NbWgyxP79+zF16lQcOnQIu3fvxt27dzFgwACUlZVplBs0aBAuX76sTtu3bzflrdY5zmkgIiJJs8Qulzt27ND4nJaWBg8PDxw5cgS9e/dW58vlcigUCoPqlhL2NBARkaSp0MCoVBslJSUAAFdXV438ffv2wcPDA+3atcOkSZNQVFRUq+tYG5MHDfqM+xAREZmKUsiMSgBQWlqqkSoqHr6KpRACsbGx6NmzJwICAtT5ERER+Pzzz7F371588MEHyMrKQr9+/fSqUypMHjToO+5DRERU13x8fODi4qJOKSkPX3Y7JiYGx48fx/r16zXyR44ciSFDhiAgIACRkZH47rvvcObMGWzbts1czbc4k89p0Hfch4iIyBRqM6ehoKAAzs7O6ny5XP7A81599VVs2bIFBw4cQIsWLR5Y1svLC76+vjh79qxBbbNmZp8IWdO4T7WKigqNrpvS0lJzN4mIiOoRYcTeE+Kv8s7OzhpBQ83lBV599VV888032LdvH/z9/R96TnFxMQoKCuDl5WVQ26yZWSdC1jTuc6+UlBSNriEfHx9zNomIiOoZJWRGJUNMnToVa9euxbp16+Dk5ITCwkIUFhbi9u3bAICbN29ixowZyMzMRF5eHvbt24fIyEi4ubnhb3/7mzluu06YNWioadznXvHx8SgpKVGngoICczaJiIjqGZUwZoEnw66xbNkylJSUICwsDF5eXuq0YcMGAICNjQ1OnDiBZ599Fu3atUNUVBTatWuHzMxMODk5meGu64bZhif0HfeRy+UPHUMiIiKqiSW2xhbiwVGGg4MDdu7caVCdUmTyoMGYcR8iIiKyfiYPGqZOnYp169Zh8+bN6nEfAHBxcYGDg4OpL0dERI84lRFbYxtanqqYPGhYtmwZACAsLEwjPy0tDePGjTP15YiI6BF372JNhpxDhjPL8AQREZGlWGJOA1XhhlVERCRpKhixuBOHJ4zCoIGIiCRNGDGnQTBoMAr7Z4iIiEgv7GkgIiJJq83eE2QYBg1ERCRpnAhpOQwaiIhI0tjTYDkMGoiISNK4uJPlyISVLaxQWloKFxcXlJSU6LVdKRERWSdz//+8uv4hO1+CraOdQefeKavEtoEr+bvGQBzUISIiIr1weIKIiCSNcxosh0EDERFJGoMGy2HQQEREksagwXIYNBARkaQJGP42hFW9ASAhnAhJREREemFPAxERSRqHJyyHQQMREUkagwbLYdBARESSxqDBchg0EBGRpDFosBwGDUREJGlCyCAMDAIMLU9V+PYEERER6YU9DUREJGnc5dJyGDQQEZGkcU6D5TBoICIiSeOcBsth0EBERJLGngbLYdBARESSxp4Gy+HbE0RERHpaunQp/P39YW9vj6CgIHz//fd13SSLYtBARESSJv4anjAkGdPTsGHDBkybNg2zZs1CTk4OevXqhYiICOTn55vhrqwTgwYiIpI0AUAIA5MR11m8eDEmTpyIl156CR06dEBqaip8fHywbNkyU9+S1WLQQEREkla9ToOhCQBKS0s1UkVFhc5rVFZW4siRIxgwYIBG/oABA3Dw4EGz36O1YNBARESSVj0R0tAEAD4+PnBxcVGnlJQUnde4evUqlEolPD09NfI9PT1RWFho9nu0Fnx7goiIJE0lZJAZ+cplQUEBnJ2d1flyufyB58lkmtcRQmjl1WcMGoiI6JHl7OysETTUxM3NDTY2Nlq9CkVFRVq9D9bm3LlzOH/+PHr37g0HB4daBTocniAiIkkzeBLkX8kQdnZ2CAoKwu7duzXyd+/ejR49epjwbkynuLgYTz/9NNq1a4fBgwfj8uXLAICXXnoJcXFxRtXJoIGIiCStNnMaDBEbG4uVK1fi3//+N06dOoXp06cjPz8fU6ZMMcNd1d706dPRsGFD5Ofno1GjRur8kSNHYseOHUbVyeEJIiKSNEutCDly5EgUFxcjKSkJly9fRkBAALZv3w5fX1+D67KEXbt2YefOnWjRooVGftu2bXHx4kWj6mTQQEREklabiZCGio6ORnR0tFHnWlpZWZlGD0O1q1evPnTCZ004PEFERJJmiTkNUtS7d2+sWbNG/Vkmk0GlUmHhwoXo27evUXWyp4GIiKgeWrhwIcLCwpCdnY3Kykq8+eabOHnyJK5du4b//e9/RtXJngYiIpK0qp4DQydC1nWrza9jx444fvw4nnzySYSHh6OsrAzDhw9HTk4OWrdubVSd7GkgIiJJ49bYNVMoFJgzZ47J6mPQQEREkiZg+AZUj0BHAw4cOPDA47179za4TgYNREQkaexp0C0sLEwr796VIJVKpcF1ck4DERFJmzAy1XPXr1/XSEVFRdixYwe6deuGXbt2GVUnexqIiIjqIRcXF6288PBwyOVyTJ8+HUeOHDG4TgYNREQkbcYsC/0IDE/UxN3dHadPnzbqXLMPT6SkpEAmk2HatGnmvhQRET2CuLiTbsePH9dIx44dw44dO/DKK6+gS5cuRtVp1p6GrKwsrFixAp07dzbnZYiI6BHGiZC6de3aFTKZDOK+CKl79+7497//bVSdZgsabt68ieeffx6ffvop3n//fXNdhoiIHnVCZvhwwyMQNOTm5mp8btCgAdzd3WFvb290nWYLGqZOnYohQ4bg6aeffmDQUFFRgYqKCvXn0tJSczWJiIjqIWOGGx6F4Qlz7L5plqDhiy++wE8//YSsrKyHlk1JSTHpalVERESPqn/+8596l33ttdcMrt/kQUNBQQFef/117Nq1S68ukPj4eMTGxqo/l5aWwsfHx9TNIiKi+opLQqp9+OGHepWTyWTWETQcOXIERUVFCAoKUucplUocOHAAS5YsQUVFBWxsbNTH5HK50ft6ExERcSLk/7t/HoOpmTxo6N+/P06cOKGRN378eLRv3x4zZ87UCBiIiIhMop72HFgbkwcNTk5OCAgI0MhzdHREs2bNtPKJiIhqiz0NNfvtt9+wZcsW5Ofno7KyUuPY4sWLDa6PK0ISEZG0cU6DTnv27MEzzzwDf39/nD59GgEBAcjLy4MQAk888YRRdVokaNi3b58lLkNERER/iY+PR1xcHJKSkuDk5ISvv/4aHh4eeP755zFo0CCj6uQul0REJHEyI1P9durUKURFRQEAGjZsiNu3b6Nx48ZISkrC/PnzjaqTQQMREUkbt8bWydHRUb14ore3N86fP68+dvXqVaPq5JwGIiKSNs5p0Kl79+743//+h44dO2LIkCGIi4vDiRMnsHHjRnTv3t2oOhk0EBGRtHHvCZ0WL16MmzdvAgASExNx8+ZNbNiwAW3atNF7Eaj7MWggIiJJ494TurVq1Ur970aNGmHp0qW1rpNzGoiIiOqh8ePHY8+ePVpbY9cGgwYiIpI2ToTUqbi4GEOGDEGLFi0QFxeHo0eP1rpOBg1ERCRt1XMaDE313JYtW1BYWIiEhAQcOXIEQUFB6NixI5KTk5GXl2dUnQwaiIhI0mTCuGQOeXl5mDhxIvz9/eHg4IDWrVsjISFBawlnmUymlZYvX27y9jRp0gSTJ0/Gvn37cPHiRYwfPx6fffYZ2rRpY1R9nAhJRETSZkWvXP76669QqVT45JNP0KZNG/z888+YNGkSysrKsGjRIo2yaWlpGiszuri4mKdRAO7cuYPs7Gz8+OOPyMvLg6enp1H1MGggIiJps6JXLgcNGqQRCLRq1QqnT5/GsmXLtIKGJk2aQKFQmKUd1TIyMrBu3Tp8/fXXUCqVGD58OLZu3Yp+/foZVR+HJ4iIiMyopKQErq6uWvkxMTFwc3NDt27dsHz5cqhUKpNet0WLFhg8eDD++OMPfPLJJ7hy5QrS0tLw9NNPo0ED4379s6eBiIikrRbDE6WlpRrZcrkccrncJM0CgPPnz+Pjjz/GBx98oJH/3nvvoX///nBwcMCePXsQFxeHq1ev4p133jHZtWfPno0RI0agadOmJquTPQ1ERCRttXjl0sfHBy4uLuqUkpKi8xKJiYk6Jy/em7KzszXOuXTpEgYNGoQRI0bgpZde0jj2zjvvICQkBF27dlXvRLlw4UJTfSMAgMmTJ5s0YADY00BERFJXi56GgoICODs7q7Nr6mWIiYnBqFGjHliln5+f+t+XLl1C3759ERISghUrVjy0Od27d0dpaSmuXLli9CRFS2DQQERE0laLiZDOzs4aQUNN3Nzc4ObmplfVv//+O/r27YugoCCkpaXpNX8gJycH9vb2aNKkiV7XqCsMGoiISNKMWXfBXOs0XLp0CWFhYWjZsiUWLVqEP/74Q32s+k2JrVu3orCwECEhIXBwcEBGRgZmzZqFyZMnm3Q+hTkwaCAiIjKRXbt24dy5czh37hxatGihcax6DwhbW1ssXboUsbGxUKlUaNWqFZKSkjB16tS6aLJBOBGSiIikzYr2nhg3bhyEEDpTtUGDBiEnJwc3btxAWVkZTpw4gddffx0NG5r+7/jPPvsMoaGh8Pb2xsWLFwEAqamp2Lx5s1H1MWggIiKqh5YtW4bY2FgMHjwYf/75J5RKJYCqRaVSU1ONqpNBAxERSZoMRuw9UdeNtoCPP/4Yn376KWbNmgUbGxt1fnBwME6cOGFUnZzTQERE0mZFy0hbk9zcXAQGBmrly+VylJWVGVUnexqIiEjarGhOgzXx9/fH0aNHtfK/++47dOzY0ag62dNARERUD73xxhuYOnUqysvLIYTA4cOHsX79eqSkpGDlypVG1cmggYiIpM2Ktsa2JuPHj8fdu3fx5ptv4tatWxgzZgyaN2+Ojz766KGrW9aEQQMREUmaNS3uZC3u3r2Lzz//HJGRkZg0aRKuXr0KlUoFDw+PWtXLOQ1ERCRtnNOgpWHDhnjllVdQUVEBoGoZ7NoGDACDBiIikjoGDTo99dRTyMnJMWmdHJ4gIiJJ4/CEbtHR0YiLi8Nvv/2GoKAgODo6ahzv3LmzwXUyaCAiIqqHRo4cCQB47bXX1HkymQxCCMhkMvUKkYZg0EBERNLGxZ10ys3NNXmdDBqIiEja+MqlTr6+viavk0EDERFJGuc06LZmzZoHHn/xxRcNrpNBAxERSRt7GnR6/fXXNT7fuXMHt27dgp2dHRo1amRU0MBXLomIiOqh69eva6SbN2/i9OnT6NmzJ9avX29UnQwaiIhI2gzdFvsRWadBl7Zt22LevHlavRD64vAEERFJG4cnDGJjY4NLly4ZdS6DBiIikjYGDTpt2bJF47MQApcvX8aSJUsQGhpqVJ0MGoiISNL49oRuw4YN0/gsk8ng7u6Ofv364YMPPjCqTgYNRERE9ZBKpTJ5nZwISUREVA8lJSXh1q1bWvm3b99GUlKSUXUyaCAiImnjLpc6zZkzBzdv3tTKv3XrFubMmWNUnRyeICIiSeOcBt2qN6a637Fjx+Dq6mpUnQwaiIhI+h6BIEBfTZs2hUwmg0wmQ7t27TQCB6VSiZs3b2LKlClG1c2ggYiIpI2vXGpITU2FEAITJkzAnDlz4OLioj5mZ2cHPz8/hISEGFW3WYKG33//HTNnzsR3332H27dvo127dli1ahWCgoLMcTkiInqEcXhCU1RUFADA398fPXr0gK2trcnqNnnQcP36dYSGhqJv37747rvv4OHhgfPnz6NJkyamvhQRERHVoE+fPup/3759G3fu3NE47uzsbHCdJg8a5s+fDx8fH6Slpanz/Pz8TH0ZIiKiKhye0OnWrVt488038eWXX6K4uFjruFKpNLhOk79yuWXLFgQHB2PEiBHw8PBAYGAgPv300xrLV1RUoLS0VCMRERHpy9DNqowZzjCEn5+feiJidXrrrbc0yuTn5yMyMhKOjo5wc3PDa6+9hsrKSpO244033sDevXuxdOlSyOVyrFy5EnPmzIG3tzfWrFljVJ0m72m4cOECli1bhtjYWLz99ts4fPgwXnvtNcjlcp17d6ekpBj9vigREZE19jQkJSVh0qRJ6s+NGzdW/1upVGLIkCFwd3fHDz/8gOLiYkRFRUEIgY8//thkbdi6dSvWrFmDsLAwTJgwAb169UKbNm3g6+uLzz//HM8//7zBdZo8aFCpVAgODkZycjIAIDAwECdPnsSyZct0Bg3x8fGIjY1Vfy4tLYWPj4+pm0VERPWVFQYNTk5OUCgUOo/t2rULv/zyCwoKCuDt7Q0A+OCDDzBu3DjMnTvXqLkGuly7dg3+/v4AquYvXLt2DQDQs2dPvPLKK0bVafLhCS8vL3Ts2FEjr0OHDsjPz9dZXi6Xw9nZWSMRERHpqzbDE/cPj1dUVJikTfPnz0ezZs3QtWtXzJ07V2PoITMzEwEBAeqAAQAGDhyIiooKHDlyxCTXB4BWrVohLy8PANCxY0d8+eWXAKp6IIx9OcHkQUNoaChOnz6tkXfmzBn4+vqa+lJERES14uPjAxcXF3VKSUmpdZ2vv/46vvjiC2RkZCAmJgapqamIjo5WHy8sLISnp6fGOU2bNoWdnR0KCwtrff1q48ePx7FjxwBU9epXz22YPn063njjDaPqNPnwxPTp09GjRw8kJyfjueeew+HDh7FixQqsWLHC1JciIiKq1fBEQUGBRg+3XC7XWTwxMfGh8++ysrIQHByM6dOnq/M6d+6Mpk2b4h//+Ie69wGAzuWda1r22Vj3tqNv37749ddfkZ2djdatW6NLly5G1WnyoKFbt2745ptvEB8fj6SkJPj7+yM1NdWoCRdEREQPVYugQd9h8ZiYGIwaNeqBZWpaXqB79+4AgHPnzqFZs2ZQKBT48ccfNcpcv34dd+7c0eqBMJXy8nK0bNkSLVu2rFU9ZlkRcujQoRg6dKg5qiYiItJgiRUh3dzc4ObmZthJf8nJyQFQNecPAEJCQjB37lxcvnxZnbdr1y7I5XKTrpysVCqRnJyM5cuX48qVKzhz5gxatWqFd999F35+fpg4caLBdXJrbCIikjYr2ho7MzMTH374IY4ePYrc3Fx8+eWXePnll/HMM8+o/8ofMGAAOnbsiLFjxyInJwd79uzBjBkzMGnSJJO+DDB37lykp6djwYIFsLOzU+d36tQJK1euNKpOBg1ERCRp1rS4k1wux4YNGxAWFoaOHTti9uzZmDRpEtavX68uY2Njg23btsHe3h6hoaF47rnnMGzYMCxatMikbVmzZg1WrFiB559/HjY2Nur8zp0749dffzWqTu5ySUREZCJPPPEEDh069NByLVu2xLfffmvWtvz+++9o06aNVr5KpdLah0Jf7GkgIiJps6LhCWvy+OOP4/vvv9fK/+qrrxAYGGhUnexpICIiabPCFSGtQUJCAsaOHYvff/8dKpUKGzduxOnTp7FmzRqjeznY00BERJImMzLVd5GRkdiwYQO2b98OmUyG2bNn49SpU9i6dSvCw8ONqpM9DUREJG3sadBw4cIF+Pv7QyaTYeDAgRg4cKDJ6mZPAxERSZo1vT1hDdq2bYs//vhD/XnkyJG4cuWKSepm0EBERFSPCKEZEW3fvh1lZWUmqZvDE0REJG0cnrAYBg1ERCR9DALUZDKZ1sZXptoIi0EDERFJmiX2npASIQTGjRun3rGzvLwcU6ZMgaOjo0a5jRs3Glw3gwYiIpI2Dk9oiIqK0vj8wgsvmKxuBg1ERCRp7GnQlJaWZra6+fYEERER6YU9DUREJG0cnrAYBg1ERCRpHJ6wHAYNREQkbexpsBgGDUREJG0MGiyGQQMREUkahycsh29PEBERkV7Y00BERNLG4QmLYdBARESSJhMCMmFYFGBoearCoIGIiKSNPQ0Ww6CBiIgkjRMhLYdBAxERSRt7GiyGb08QERGRXtjTQEREksbhCcth0EBERNLG4QmLYdBARESSxp4Gy2HQQERE0saeBovhREgiIpK86t4GfZO57Nu3DzKZTGfKysr6//bqOL58+XLzNcxE2NNARERkIj169MDly5c18t59913897//RXBwsEZ+WloaBg0apP7s4uJikTbWBoMGIiKSNiGqkqHnmIGdnR0UCoX68507d7BlyxbExMRAJpNplG3SpIlGWSng8AQREUmaoUMT5h6iuNeWLVtw9epVjBs3TutYTEwM3Nzc0K1bNyxfvhwqlcoyjaoF9jQQEZG01WIiZGlpqUa2XC6HXC43SbMAYNWqVRg4cCB8fHw08t977z30798fDg4O2LNnD+Li4nD16lW88847Jru2ObCngYiIJE2mMi4BgI+PD1xcXNQpJSVF5zUSExNrnOBYnbKzszXO+e2337Bz505MnDhRq7533nkHISEh6Nq1K+Li4pCUlISFCxea/LsxNfY0EBGRtNWip6GgoADOzs7q7Jp6GWJiYjBq1KgHVunn56fxOS0tDc2aNcMzzzzz0OZ0794dpaWluHLlCjw9PR9avq4waCAiokeWs7OzRtBQEzc3N7i5ueldrxACaWlpePHFF2Fra/vQ8jk5ObC3t0eTJk30vkZdYNBARESSZo0rQu7duxe5ubk6hya2bt2KwsJChISEwMHBARkZGZg1axYmT55s0vkU5sCggYiIpM2KXrmstmrVKvTo0QMdOnTQOmZra4ulS5ciNjYWKpUKrVq1QlJSEqZOnWrWNpkCgwYiIpI0a+xpWLduXY3HBg0apLGok5QwaCAiImnj3hMWw6CBiIgkzRp7GuorrtNAREREejF50HD37l2888478Pf3h4ODg3qChxSWxyQiIgmqnghpaCKDmXx4Yv78+Vi+fDlWr16Nxx9/HNnZ2Rg/fjxcXFzw+uuvm/pyRET0iOPwhOWYPGjIzMzEs88+iyFDhgCoWiFr/fr1WstrEhERmQQnQlqMyYcnevbsiT179uDMmTMAgGPHjuGHH37A4MGDdZavqKhAaWmpRiIiItKXNe9yWd+YvKdh5syZKCkpQfv27WFjYwOlUom5c+di9OjROsunpKRgzpw5pm4GERE9KlSiKhl6DhnM5D0NGzZswNq1a7Fu3Tr89NNPWL16NRYtWoTVq1frLB8fH4+SkhJ1KigoMHWTiIiIyARM3tPwxhtv4K233lLvBtapUydcvHgRKSkpiIqK0ipv6r3LiYjoEcM5DRZj8qDh1q1baNBAswPDxsaGr1wSEZFZyGDE2xNmaUn9Z/KgITIyEnPnzkXLli3x+OOPIycnB4sXL8aECRNMfSkiIiKr3LCqvjJ50PDxxx/j3XffRXR0NIqKiuDt7Y2XX34Zs2fPNvWliIiIuE6DBZk8aHByckJqaipSU1NNXTURERHVIW5YRURE0saJkBbDoIGIiCRNJgRkBs5RMLQ8VWHQQERE0qb6Kxl6DhmMQQMREUkaexosh0EDERFJG+c0WIzJl5EmIiKi+ok9DUREJG1c3MliGDQQEdVjwd+9rXfZ7IhkM7bEfLi4k+UwaCAiImljT4PFMGggIiJJk6mqkqHnkOEYNBARkbSxp8Fi+PYEERER6YU9DUREJG1cp8FiGDQQEZGkcUVIy2HQQERE0sY5DRbDOQ1ERCRtAv+/aZW+yYwxw9y5c9GjRw80atQITZo00VkmPz8fkZGRcHR0hJubG1577TVUVlZqlDlx4gT69OkDBwcHNG/eHElJSRB1HOywp4GIiCTN2oYnKisrMWLECISEhGDVqlVax5VKJYYMGQJ3d3f88MMPKC4uRlRUFIQQ+PjjjwEApaWlCA8PR9++fZGVlYUzZ85g3LhxcHR0RFxcnNna/jAMGoiIiExozpw5AID09HSdx3ft2oVffvkFBQUF8Pb2BgB88MEHGDduHObOnQtnZ2d8/vnnKC8vR3p6OuRyOQICAnDmzBksXrwYsbGxkMlklrodDRyeICIiaRP4/3kNeqeqU0tLSzVSRUWF2ZubmZmJgIAAdcAAAAMHDkRFRQWOHDmiLtOnTx/I5XKNMpcuXUJeXp7Z21gTBg1ERCRtBgcM/z9x0sfHBy4uLuqUkpJi9uYWFhbC09NTI69p06aws7NDYWFhjWWqP1eXqQsMGoiISNoMnQRZnQAUFBSgpKREneLj43VeIjExETKZ7IEpOztb7ybrGl4QQmjk31+mehJkXQ1NAJzTQEREElebiZDOzs5wdnZ+aPmYmBiMGjXqgWX8/Pz0urZCocCPP/6okXf9+nXcuXNH3ZugUCi0ehSKiooAQKsHwpIYNBARkbRZYJ0GNzc3uLm5GXaNGoSEhGDu3Lm4fPkyvLy8AFRNjpTL5QgKClKXefvtt1FZWQk7Ozt1GW9vb72DE3Pg8AQREZEJ5efn4+jRo8jPz4dSqcTRo0dx9OhR3Lx5EwAwYMAAdOzYEWPHjkVOTg727NmDGTNmYNKkSepejzFjxkAul2PcuHH4+eef8c033yA5OblO35wA2NNARERSZ2UrQs6ePRurV69Wfw4MDAQAZGRkICwsDDY2Nti2bRuio6MRGhoKBwcHjBkzBosWLVKf4+Ligt27d2Pq1KkIDg5G06ZNERsbi9jYWLO1Wx8MGoiISNqsLGhIT0+vcY2Gai1btsS33377wDKdOnXCgQMHTNiy2mPQQERE0qYCYGiPvcocDan/GDQQEZGkWdsy0vUZgwYiIpI2KxueqM/49gQRERHphT0NREQkbSoByAzsOVCxp8EYDBqIiEjaODxhMQwaiIhI4owIGsCgwRgMGoiISNrY02AxDBqIiEjaVAIG9xxwToNRGDQQ1ZHg797Wu2x2RLIZW0L1GX92yJQYNBARkbQJVVUy9BwyGIMGIiKSNs5psBgGDUREJG2c02AxDBqIiEja2NNgMQwaiIhI2gSMCBrM0pJ6j3tPEBERkV7Y00BERNLG4QmLYdBARETSplIBMPAVShVfuTQGgwYiIpI29jRYjMFzGg4cOIDIyEh4e3tDJpNh06ZNGseFEEhMTIS3tzccHBwQFhaGkydPmqq9REREmqqDBkMTGczgoKGsrAxdunTBkiVLdB5fsGABFi9ejCVLliArKwsKhQLh4eG4ceNGrRtLRESkRSWMS2Qwg4cnIiIiEBERofOYEAKpqamYNWsWhg8fDgBYvXo1PD09sW7dOrz88su1ay0RERHVGZO+cpmbm4vCwkIMGDBAnSeXy9GnTx8cPHhQ5zkVFRUoLS3VSERERPoSQmVUIsOZNGgoLCwEAHh6emrke3p6qo/dLyUlBS4uLurk4+NjyiYREVF9J4wYmuCcBqOYZXEnmUym8VkIoZVXLT4+HiUlJepUUFBgjiYREVF9xYmQFmPSVy4VCgWAqh4HLy8vdX5RUZFW70M1uVwOuVxuymYQEdGjRKUCZNwa2xJM2tPg7+8PhUKB3bt3q/MqKyuxf/9+9OjRw5SXIiIiqsKeBosxuKfh5s2bOHfunPpzbm4ujh49CldXV7Rs2RLTpk1DcnIy2rZti7Zt2yI5ORmNGjXCmDFjTNpwIiIisiyDexqys7MRGBiIwMBAAEBsbCwCAwMxe/ZsAMCbb76JadOmITo6GsHBwfj999+xa9cuODk5mbblREREAIRKZVQyl7lz56JHjx5o1KgRmjRponX82LFjGD16NHx8fODg4IAOHTrgo48+0iiTl5cHmUymlXbs2GG2duvD4J6GsLAwiAd068hkMiQmJiIxMbE27SIiItKPEDB4r2szDk9UVlZixIgRCAkJwapVq7SOHzlyBO7u7li7di18fHxw8OBBTJ48GTY2NoiJidEo+9///hePP/64+rOrq6vZ2q0P7j1BRETSphKAzHqChjlz5gAA0tPTdR6fMGGCxudWrVohMzMTGzdu1AoamjVrpn7JwBqY5ZVLIiIiixGi6m0Ig5J1TYQsKSnR2YvwzDPPwMPDA6GhofjPf/5TBy3TxJ4GIiKSNKESEAb2NFQPs9+/CnFdLAOQmZmJL7/8Etu2bVPnNW7cGIsXL0ZoaCgaNGiALVu2YOTIkVi9ejVeeOEFi7bvXuxpICKiR5aPj4/GqsQpKSk6yyUmJuqcmHhvys7ONvj6J0+exLPPPovZs2cjPDxcne/m5obp06fjySefRHBwMJKSkhAdHY0FCxYYfa+mwJ4GIiKSNqECYNziTgUFBXB2dlZn19TLEBMTg1GjRj2wSj8/P4Oa8Msvv6Bfv36YNGkS3nnnnYeW7969O1auXGnQNUyNQQMREUlabYYnnJ2dNYKGmri5ucHNzc2o9uly8uRJ9OvXD1FRUZg7d65e5+Tk5GistlwXrC5oqGmciai+Ud6q0Lss/3sgKar+uX3Qa/qmcFdUGLws9F3cMVNrgPz8fFy7dg35+flQKpU4evQoAKBNmzZo3LgxTp48ib59+2LAgAGIjY1Vb+hoY2MDd3d3AMDq1atha2uLwMBANGjQAFu3bsU///lPzJ8/32zt1ouwMgUFBdUv3DIxMTEx1YNUUFBglt8Xt2/fFgqFwuh2KRQKcfv2bZO3KyoqSuf1MjIyhBBCJCQk6Dzu6+urriM9PV106NBBNGrUSDg5OYmgoCDx2WefmbythpIJYV3vnahUKly6dAlOTk4aO2OWlpbCx8dHa/ypPqiv91Zf7wvgvUlRfb0vwHrvTQiBGzduwNvbGw0amGfefXl5OSorK406187ODvb29iZuUf1mdcMTDRo0QIsWLWo8ru/4kxTV13urr/cF8N6kqL7eF2Cd9+bi4mLW+u3t7fmL34L4yiURERHphUEDERER6UUyQYNcLkdCQoLFV+qyhPp6b/X1vgDemxTV1/sC6ve9kXWxuomQREREZJ0k09NAREREdYtBAxEREemFQQMRERHphUEDERER6UUSQcPSpUvh7+8Pe3t7BAUF4fvvv6/rJtWarm1WFQpFXTfLKAcOHEBkZCS8vb0hk8mwadMmjeNCCCQmJsLb2xsODg4ICwvDyZMn66axBnrYvY0bN07rOXbv3r1uGmuAlJQUdOvWDU5OTvDw8MCwYcNw+vRpjTJSfW763JsUn9uyZcvQuXNn9QJOISEh+O6779THpfq8SFqsPmjYsGEDpk2bhlmzZiEnJwe9evVCREQE8vPz67pptfb444/j8uXL6nTixIm6bpJRysrK0KVLFyxZskTn8QULFmDx4sVYsmQJsrKyoFAoEB4ejhs3bli4pYZ72L0BwKBBgzSe4/bt2y3YQuPs378fU6dOxaFDh7B7927cvXsXAwYMQFlZmbqMVJ+bPvcGSO+5tWjRAvPmzUN2djays7PRr18/PPvss+rAQKrPiySm7ra90M+TTz4ppkyZopHXvn178dZbb9VRi0wjISFBdOnSpa6bYXIAxDfffKP+rFKphEKhEPPmzVPnlZeXCxcXF7F8+fI6aKHx7r83Iao2pnn22WfrpD2mVFRUJACI/fv3CyHq13O7/96EqD/PrWnTpmLlypX16nmRdbPqnobKykocOXIEAwYM0MgfMGAADh48WEetMp2zZ8/C29sb/v7+GDVqFC5cuFDXTTK53NxcFBYWajxDuVyOPn361ItnCAD79u2Dh4cH2rVrh0mTJqGoqKium2SwkpISAICrqyuA+vXc7r+3alJ+bkqlEl988QXKysoQEhJSr54XWTerDhquXr0KpVIJT09PjXxPT0/1/uNS9dRTT2HNmjXYuXMnPv30UxQWFqJHjx4oLi6u66aZVPVzqo/PEAAiIiLw+eefY+/evfjggw+QlZWFfv36oaKioq6bpjchBGJjY9GzZ08EBAQAqD/PTde9AdJ9bidOnEDjxo0hl8sxZcoUfPPNN+jYsWO9eV5k/axul0td7t0iG6j6H8H9eVITERGh/nenTp0QEhKC1q1bY/Xq1YiNja3DlplHfXyGADBy5Ej1vwMCAhAcHAxfX19s27YNw4cPr8OW6S8mJgbHjx/HDz/8oHVM6s+tpnuT6nN77LHHcPToUfz555/4+uuvERUVhf3796uPS/15kfWz6p4GNzc32NjYaEXKRUVFWhG11Dk6OqJTp044e/ZsXTfFpKrfCHkUniEAeHl5wdfXVzLP8dVXX8WWLVuQkZGhsSV9fXhuNd2bLlJ5bnZ2dmjTpg2Cg4ORkpKCLl264KOPPqoXz4ukwaqDBjs7OwQFBWH37t0a+bt370aPHj3qqFXmUVFRgVOnTsHLy6uum2JS/v7+UCgUGs+wsrIS+/fvr3fPEACKi4tRUFBg9c9RCIGYmBhs3LgRe/fuhb+/v8ZxKT+3h92bLlJ5bvcTQqCiokLSz4skps6mYOrpiy++ELa2tmLVqlXil19+EdOmTROOjo4iLy+vrptWK3FxcWLfvn3iwoUL4tChQ2Lo0KHCyclJkvd148YNkZOTI3JycgQAsXjxYpGTkyMuXrwohBBi3rx5wsXFRWzcuFGcOHFCjB49Wnh5eYnS0tI6bvnDPejebty4IeLi4sTBgwdFbm6uyMjIECEhIaJ58+ZWf2+vvPKKcHFxEfv27ROXL19Wp1u3bqnLSPW5PezepPrc4uPjxYEDB0Rubq44fvy4ePvtt0WDBg3Erl27hBDSfV4kLVYfNAghxL/+9S/h6+sr7OzsxBNPPKHx6pRUjRw5Unh5eQlbW1vh7e0thg8fLk6ePFnXzTJKRkaGAKCVoqKihBBVr+8lJCQIhUIh5HK56N27tzhx4kTdNlpPD7q3W7duiQEDBgh3d3dha2srWrZsKaKiokR+fn5dN/uhdN0TAJGWlqYuI9Xn9rB7k+pzmzBhgvr/g+7u7qJ///7qgEEI6T4vkhZujU1ERER6seo5DURERGQ9GDQQERGRXhg0EBERkV4YNBAREZFeGDQQERGRXhg0EBERkV4YNBAREZFeGDQQERGRXhg0EBERkV4YNBAREZFeGDQQERGRXhg0EBERkV7+D1XEcujwYjXZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "x = batch['X'][0].reshape(11, 34).cpu().numpy()  # adjust reshape as needed\n",
    "y = batch['y'][0]\n",
    "\n",
    "# Mask zero values\n",
    "masked_x = np.ma.masked_where(x == 0, x)\n",
    "\n",
    "# Create a colormap: 'viridis' with white for masked (zero) values\n",
    "cmap = plt.cm.viridis\n",
    "cmap.set_bad(color='white')  # White for masked areas\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(masked_x, cmap=cmap, aspect='auto')\n",
    "plt.title(f\"Input visualization (Label: {y.item()})\")\n",
    "plt.colorbar(label=\"Feature value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29321dd",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc15976",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \"\"\" Simple Feed-Forward Net \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.name = \"BasicDenseNetwork_testing\"\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(11 * 34, 1024)  # SWITCH TO 1024\n",
    "        self.fc2 = torch.nn.Linear(1024, 512)      # SWITCH TO 1024\n",
    "        self.fc3 = torch.nn.Linear(512, 256)\n",
    "        self.fc4 = torch.nn.Linear(256, 128)\n",
    "        self.fc5 = torch.nn.Linear(128, 34)\n",
    "        \n",
    "        self.relu_1 = torch.nn.LeakyReLU()\n",
    "        self.relu_2 = torch.nn.LeakyReLU()\n",
    "        self.relu_3 = torch.nn.LeakyReLU()\n",
    "        self.relu_4 = torch.nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "            \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu_2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu_3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.relu_4(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b5d8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigAttentionNet(torch.nn.Module):\n",
    "    \"\"\" Attention Layer into Bigger feed-forward net. \"\"\"\n",
    "\n",
    "    def __init__(self, n_heads):\n",
    "        super(BigAttentionNet, self).__init__()\n",
    "        \n",
    "        self.name = f\"MHA-{n_heads}\"\n",
    "#         print(self.name)\n",
    "        \n",
    "        self.mha1 = torch.nn.MultiheadAttention(embed_dim=374, \n",
    "                                                num_heads=n_heads,  # 1, 11, or 34 are doable\n",
    "                                                dropout=0.0,   # Default: 0.0.\n",
    "                                                add_zero_attn=False,  # Default: False - Have this false, from not so many experiments, it seems like it slows down learning accuracy by a almost unoticeable bit\n",
    "                                               )\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(11 * 34, 4096)   # EXTRA LAYER\n",
    "        self.fc2 = torch.nn.Linear(4096, 2048)      # EXTRA LAYER\n",
    "        self.fc3 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc4 = torch.nn.Linear(1024, 512)\n",
    "        self.fc5 = torch.nn.Linear(512, 256)\n",
    "        self.fc6 = torch.nn.Linear(256, 128)\n",
    "        self.fc7 = torch.nn.Linear(128, 34)\n",
    "        \n",
    "        self.relu_1 = torch.nn.LeakyReLU()\n",
    "        self.relu_2 = torch.nn.LeakyReLU()\n",
    "        self.relu_3 = torch.nn.LeakyReLU()\n",
    "        self.relu_4 = torch.nn.LeakyReLU()\n",
    "        self.relu_5 = torch.nn.LeakyReLU()\n",
    "        self.relu_6 = torch.nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape(1, batch_size, 374)  #  => x.shape[0] = Batch Size\n",
    "        attn_output, attn_output_weights = self.mha1(query=x, key=x, value=x, need_weights=False)  # attn_output_weights = None, if need_weights=False\n",
    "        x = attn_output.reshape(batch_size, 374)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu_2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu_3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.relu_4(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = self.relu_5(x)\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        x = self.relu_6(x)\n",
    "        \n",
    "        x = self.fc7(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80e33dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=374, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc5): Linear(in_features=128, out_features=34, bias=True)\n",
       "  (relu_1): LeakyReLU(negative_slope=0.01)\n",
       "  (relu_2): LeakyReLU(negative_slope=0.01)\n",
       "  (relu_3): LeakyReLU(negative_slope=0.01)\n",
       "  (relu_4): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = Net().to(device)  # SWITCH ATTENTION\n",
    "# model = BigNet().to(DEVICE)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)  # Loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loaded_epoch = 0\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac440e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077410"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f7efa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      2\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)  \u001b[38;5;66;03m# 等价于 model.forward(inputs)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputs\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "sample_input = torch.randn(32, 3, 64, 64).to(device)  # 根据你模型的输入形状\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(sample_input)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0c8bd",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3bbb854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_model(model, train_loader, validation_loader, criterion, optimizer, device, epochs):\n",
    "    \"\"\"\n",
    "    Train the model and validate after each epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: The PyTorch model to train.\n",
    "        train_loader: DataLoader for the training dataset.\n",
    "        validation_loader: DataLoader for the validation dataset.\n",
    "        criterion: Loss function.\n",
    "        optimizer: Optimizer for training.\n",
    "        device: Device to train on (CPU or GPU).\n",
    "        epochs: Number of epochs to train.\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Training loop\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch['X'].to(device), batch['y'].to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss and accuracy\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Print training stats\n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        # Validation loop\n",
    "        validate_model(model, validation_loader, criterion, device)\n",
    "\n",
    "def validate_model(model, validation_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate the model on the validation dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: The PyTorch model to validate.\n",
    "        validation_loader: DataLoader for the validation dataset.\n",
    "        criterion: Loss function.\n",
    "        device: Device to validate on (CPU or GPU).\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    validation_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in validation_loader:\n",
    "            inputs, labels = batch['X'].to(device), batch['y'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Accumulate loss and accuracy\n",
    "            validation_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    validation_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Loss: {validation_loss:.4f}, Accuracy: {validation_accuracy:.2f}%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86d2461c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 4415.4887, Accuracy: 2.82%\n",
      "Validation Loss: 881.6554, Accuracy: 2.94%\n",
      "Epoch 2/100, Loss: 4409.3244, Accuracy: 2.95%\n",
      "Validation Loss: 881.6769, Accuracy: 2.94%\n",
      "Epoch 3/100, Loss: 4408.5781, Accuracy: 2.77%\n",
      "Validation Loss: 881.5956, Accuracy: 2.94%\n",
      "Epoch 4/100, Loss: 4408.4916, Accuracy: 2.70%\n",
      "Validation Loss: 881.6188, Accuracy: 2.94%\n",
      "Epoch 5/100, Loss: 4410.9726, Accuracy: 2.76%\n",
      "Validation Loss: 881.5993, Accuracy: 2.94%\n",
      "Epoch 6/100, Loss: 4408.5147, Accuracy: 2.83%\n",
      "Validation Loss: 881.5980, Accuracy: 2.94%\n",
      "Epoch 7/100, Loss: 4409.4153, Accuracy: 2.89%\n",
      "Validation Loss: 882.2313, Accuracy: 2.94%\n",
      "Epoch 8/100, Loss: 4410.1892, Accuracy: 2.66%\n",
      "Validation Loss: 881.6233, Accuracy: 2.94%\n",
      "Epoch 9/100, Loss: 4409.6387, Accuracy: 2.91%\n",
      "Validation Loss: 882.2626, Accuracy: 2.94%\n",
      "Epoch 10/100, Loss: 4409.2690, Accuracy: 2.78%\n",
      "Validation Loss: 881.6025, Accuracy: 2.94%\n",
      "Epoch 11/100, Loss: 4409.6583, Accuracy: 2.83%\n",
      "Validation Loss: 881.6080, Accuracy: 2.87%\n",
      "Epoch 12/100, Loss: 4413.2165, Accuracy: 2.88%\n",
      "Validation Loss: 881.7016, Accuracy: 2.94%\n",
      "Epoch 13/100, Loss: 4411.0503, Accuracy: 2.87%\n",
      "Validation Loss: 882.9052, Accuracy: 2.94%\n",
      "Epoch 14/100, Loss: 4411.7582, Accuracy: 2.98%\n",
      "Validation Loss: 881.8477, Accuracy: 2.94%\n",
      "Epoch 15/100, Loss: 4410.3076, Accuracy: 2.96%\n",
      "Validation Loss: 881.5674, Accuracy: 2.95%\n",
      "Epoch 16/100, Loss: 4414.9898, Accuracy: 2.91%\n",
      "Validation Loss: 882.1378, Accuracy: 2.94%\n",
      "Epoch 17/100, Loss: 4411.8079, Accuracy: 3.06%\n",
      "Validation Loss: 881.9419, Accuracy: 2.94%\n",
      "Epoch 18/100, Loss: 4409.9676, Accuracy: 2.91%\n",
      "Validation Loss: 881.3139, Accuracy: 2.94%\n",
      "Epoch 19/100, Loss: 4418.0509, Accuracy: 2.84%\n",
      "Validation Loss: 882.0484, Accuracy: 3.63%\n",
      "Epoch 20/100, Loss: 4411.5103, Accuracy: 2.99%\n",
      "Validation Loss: 881.7319, Accuracy: 2.94%\n",
      "Epoch 21/100, Loss: 4410.9935, Accuracy: 3.12%\n",
      "Validation Loss: 881.6503, Accuracy: 2.94%\n",
      "Epoch 22/100, Loss: 4411.2865, Accuracy: 3.15%\n",
      "Validation Loss: 881.4578, Accuracy: 3.79%\n",
      "Epoch 23/100, Loss: 4414.6833, Accuracy: 3.05%\n",
      "Validation Loss: 881.9794, Accuracy: 2.94%\n",
      "Epoch 24/100, Loss: 4410.2776, Accuracy: 3.25%\n",
      "Validation Loss: 881.0159, Accuracy: 4.01%\n",
      "Epoch 25/100, Loss: 4414.8683, Accuracy: 2.97%\n",
      "Validation Loss: 881.9669, Accuracy: 2.99%\n",
      "Epoch 26/100, Loss: 4411.2760, Accuracy: 3.34%\n",
      "Validation Loss: 881.4388, Accuracy: 3.28%\n",
      "Epoch 27/100, Loss: 4413.2901, Accuracy: 3.20%\n",
      "Validation Loss: 882.2299, Accuracy: 3.99%\n",
      "Epoch 28/100, Loss: 4401.2823, Accuracy: 3.27%\n",
      "Validation Loss: 877.0981, Accuracy: 3.99%\n",
      "Epoch 29/100, Loss: 4357.8662, Accuracy: 3.97%\n",
      "Validation Loss: 867.4697, Accuracy: 3.92%\n",
      "Epoch 30/100, Loss: 4339.4343, Accuracy: 4.06%\n",
      "Validation Loss: 865.5290, Accuracy: 4.07%\n",
      "Epoch 31/100, Loss: 4342.2295, Accuracy: 3.99%\n",
      "Validation Loss: 866.9585, Accuracy: 4.17%\n",
      "Epoch 32/100, Loss: 4331.7747, Accuracy: 4.11%\n",
      "Validation Loss: 869.5507, Accuracy: 4.09%\n",
      "Epoch 33/100, Loss: 4345.6332, Accuracy: 3.92%\n",
      "Validation Loss: 866.2975, Accuracy: 4.19%\n",
      "Epoch 34/100, Loss: 4332.4529, Accuracy: 4.16%\n",
      "Validation Loss: 866.8907, Accuracy: 4.64%\n",
      "Epoch 35/100, Loss: 4382.7513, Accuracy: 3.67%\n",
      "Validation Loss: 881.3945, Accuracy: 3.13%\n",
      "Epoch 36/100, Loss: 4368.6946, Accuracy: 3.87%\n",
      "Validation Loss: 872.2291, Accuracy: 3.79%\n",
      "Epoch 37/100, Loss: 4350.1150, Accuracy: 4.00%\n",
      "Validation Loss: 874.3229, Accuracy: 4.04%\n",
      "Epoch 38/100, Loss: 4356.0596, Accuracy: 3.86%\n",
      "Validation Loss: 880.0203, Accuracy: 3.49%\n",
      "Epoch 39/100, Loss: 4354.0807, Accuracy: 4.02%\n",
      "Validation Loss: 869.7246, Accuracy: 4.42%\n",
      "Epoch 40/100, Loss: 4346.5868, Accuracy: 3.82%\n",
      "Validation Loss: 865.5385, Accuracy: 4.51%\n",
      "Epoch 41/100, Loss: 4359.1827, Accuracy: 3.99%\n",
      "Validation Loss: 867.4080, Accuracy: 4.09%\n",
      "Epoch 42/100, Loss: 4337.2887, Accuracy: 4.17%\n",
      "Validation Loss: 864.6933, Accuracy: 4.37%\n",
      "Epoch 43/100, Loss: 4329.1839, Accuracy: 4.29%\n",
      "Validation Loss: 864.4699, Accuracy: 4.16%\n",
      "Epoch 44/100, Loss: 4325.6160, Accuracy: 4.16%\n",
      "Validation Loss: 867.6748, Accuracy: 3.98%\n",
      "Epoch 45/100, Loss: 4319.1565, Accuracy: 4.24%\n",
      "Validation Loss: 864.6389, Accuracy: 4.27%\n",
      "Epoch 46/100, Loss: 4318.6665, Accuracy: 4.15%\n",
      "Validation Loss: 862.6915, Accuracy: 4.77%\n",
      "Epoch 47/100, Loss: 4329.7846, Accuracy: 4.19%\n",
      "Validation Loss: 865.5366, Accuracy: 4.71%\n",
      "Epoch 48/100, Loss: 4323.4651, Accuracy: 4.36%\n",
      "Validation Loss: 863.2379, Accuracy: 4.38%\n",
      "Epoch 49/100, Loss: 4317.8933, Accuracy: 4.21%\n",
      "Validation Loss: 865.4820, Accuracy: 4.43%\n",
      "Epoch 50/100, Loss: 4326.2440, Accuracy: 4.38%\n",
      "Validation Loss: 867.6581, Accuracy: 4.38%\n",
      "Epoch 51/100, Loss: 4313.1829, Accuracy: 4.18%\n",
      "Validation Loss: 867.0720, Accuracy: 4.49%\n",
      "Epoch 52/100, Loss: 4371.7239, Accuracy: 4.22%\n",
      "Validation Loss: 864.7509, Accuracy: 4.32%\n",
      "Epoch 53/100, Loss: 4313.0963, Accuracy: 4.43%\n",
      "Validation Loss: 865.3756, Accuracy: 4.17%\n",
      "Epoch 54/100, Loss: 4306.1811, Accuracy: 4.32%\n",
      "Validation Loss: 861.8701, Accuracy: 4.44%\n",
      "Epoch 55/100, Loss: 4300.2521, Accuracy: 4.26%\n",
      "Validation Loss: 860.7064, Accuracy: 4.41%\n",
      "Epoch 56/100, Loss: 4611.5000, Accuracy: 4.42%\n",
      "Validation Loss: 863.3806, Accuracy: 4.46%\n",
      "Epoch 57/100, Loss: 4306.4096, Accuracy: 4.35%\n",
      "Validation Loss: 863.9648, Accuracy: 4.09%\n",
      "Epoch 58/100, Loss: 4302.6058, Accuracy: 4.31%\n",
      "Validation Loss: 867.1117, Accuracy: 4.31%\n",
      "Epoch 59/100, Loss: 4302.5779, Accuracy: 4.29%\n",
      "Validation Loss: 862.2048, Accuracy: 4.52%\n",
      "Epoch 60/100, Loss: 4302.2531, Accuracy: 4.38%\n",
      "Validation Loss: 861.8621, Accuracy: 4.42%\n",
      "Epoch 61/100, Loss: 4361.5526, Accuracy: 4.45%\n",
      "Validation Loss: 875.6379, Accuracy: 3.23%\n",
      "Epoch 62/100, Loss: 4324.4745, Accuracy: 4.41%\n",
      "Validation Loss: 863.9284, Accuracy: 4.23%\n",
      "Epoch 63/100, Loss: 4305.9320, Accuracy: 4.39%\n",
      "Validation Loss: 863.1765, Accuracy: 4.58%\n",
      "Epoch 64/100, Loss: 4307.4997, Accuracy: 4.52%\n",
      "Validation Loss: 865.1986, Accuracy: 4.29%\n",
      "Epoch 65/100, Loss: 4303.5284, Accuracy: 4.51%\n",
      "Validation Loss: 862.8993, Accuracy: 4.88%\n",
      "Epoch 66/100, Loss: 4309.4439, Accuracy: 4.53%\n",
      "Validation Loss: 866.8221, Accuracy: 4.27%\n",
      "Epoch 67/100, Loss: 4309.9628, Accuracy: 4.38%\n",
      "Validation Loss: 861.7559, Accuracy: 4.38%\n",
      "Epoch 68/100, Loss: 11328.9408, Accuracy: 4.30%\n",
      "Validation Loss: 870.7529, Accuracy: 3.74%\n",
      "Epoch 69/100, Loss: 4332.9326, Accuracy: 4.34%\n",
      "Validation Loss: 866.8924, Accuracy: 4.52%\n",
      "Epoch 70/100, Loss: 4321.6593, Accuracy: 4.13%\n",
      "Validation Loss: 865.5813, Accuracy: 4.52%\n",
      "Epoch 71/100, Loss: 4312.3199, Accuracy: 4.22%\n",
      "Validation Loss: 862.4926, Accuracy: 4.52%\n",
      "Epoch 72/100, Loss: 4316.3465, Accuracy: 4.21%\n",
      "Validation Loss: 865.0191, Accuracy: 4.31%\n",
      "Epoch 73/100, Loss: 4310.1731, Accuracy: 4.09%\n",
      "Validation Loss: 869.5127, Accuracy: 4.04%\n",
      "Epoch 74/100, Loss: 4301.6426, Accuracy: 4.35%\n",
      "Validation Loss: 861.0242, Accuracy: 4.57%\n",
      "Epoch 75/100, Loss: 4294.6124, Accuracy: 4.45%\n",
      "Validation Loss: 860.3502, Accuracy: 4.54%\n",
      "Epoch 76/100, Loss: 4318.7495, Accuracy: 4.43%\n",
      "Validation Loss: 860.4492, Accuracy: 4.47%\n",
      "Epoch 77/100, Loss: 4300.4853, Accuracy: 4.33%\n",
      "Validation Loss: 860.2812, Accuracy: 4.62%\n",
      "Epoch 78/100, Loss: 4305.5770, Accuracy: 4.57%\n",
      "Validation Loss: 876.8160, Accuracy: 4.18%\n",
      "Epoch 79/100, Loss: 4300.5126, Accuracy: 4.45%\n",
      "Validation Loss: 860.7559, Accuracy: 4.72%\n",
      "Epoch 80/100, Loss: 4301.8630, Accuracy: 4.38%\n",
      "Validation Loss: 860.2469, Accuracy: 4.49%\n",
      "Epoch 81/100, Loss: 4296.5920, Accuracy: 4.56%\n",
      "Validation Loss: 860.5436, Accuracy: 4.51%\n",
      "Epoch 82/100, Loss: 4301.7149, Accuracy: 4.54%\n",
      "Validation Loss: 860.7262, Accuracy: 4.72%\n",
      "Epoch 83/100, Loss: 4294.8005, Accuracy: 4.50%\n",
      "Validation Loss: 864.1800, Accuracy: 4.24%\n",
      "Epoch 84/100, Loss: 4297.5019, Accuracy: 4.35%\n",
      "Validation Loss: 859.4517, Accuracy: 4.63%\n",
      "Epoch 85/100, Loss: 4288.7836, Accuracy: 4.68%\n",
      "Validation Loss: 860.1443, Accuracy: 4.47%\n",
      "Epoch 86/100, Loss: 4292.4642, Accuracy: 4.55%\n",
      "Validation Loss: 865.6980, Accuracy: 4.51%\n",
      "Epoch 87/100, Loss: 4289.3362, Accuracy: 4.66%\n",
      "Validation Loss: 858.0173, Accuracy: 4.69%\n",
      "Epoch 88/100, Loss: 4630.4193, Accuracy: 4.45%\n",
      "Validation Loss: 862.2043, Accuracy: 4.33%\n",
      "Epoch 89/100, Loss: 4300.6157, Accuracy: 4.66%\n",
      "Validation Loss: 861.6526, Accuracy: 4.27%\n",
      "Epoch 90/100, Loss: 4295.4890, Accuracy: 4.46%\n",
      "Validation Loss: 860.8272, Accuracy: 4.61%\n",
      "Epoch 91/100, Loss: 4296.5190, Accuracy: 4.59%\n",
      "Validation Loss: 859.9709, Accuracy: 4.91%\n",
      "Epoch 92/100, Loss: 4297.7592, Accuracy: 4.41%\n",
      "Validation Loss: 859.4303, Accuracy: 4.36%\n",
      "Epoch 93/100, Loss: 4290.4950, Accuracy: 4.69%\n",
      "Validation Loss: 861.7884, Accuracy: 4.39%\n",
      "Epoch 94/100, Loss: 4292.8337, Accuracy: 4.50%\n",
      "Validation Loss: 860.8434, Accuracy: 4.43%\n",
      "Epoch 95/100, Loss: 4285.5760, Accuracy: 4.64%\n",
      "Validation Loss: 859.1421, Accuracy: 4.68%\n",
      "Epoch 96/100, Loss: 4290.6806, Accuracy: 4.55%\n",
      "Validation Loss: 859.6933, Accuracy: 4.59%\n",
      "Epoch 97/100, Loss: 4309.5198, Accuracy: 4.52%\n",
      "Validation Loss: 868.6563, Accuracy: 4.28%\n",
      "Epoch 98/100, Loss: 4316.9739, Accuracy: 4.58%\n",
      "Validation Loss: 862.4696, Accuracy: 4.49%\n",
      "Epoch 99/100, Loss: 4335.2827, Accuracy: 4.62%\n",
      "Validation Loss: 861.0702, Accuracy: 4.49%\n",
      "Epoch 100/100, Loss: 4292.0071, Accuracy: 4.68%\n",
      "Validation Loss: 874.5921, Accuracy: 4.14%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, validation_loader, criterion, optimizer, device, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mjx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
